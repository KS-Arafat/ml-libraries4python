{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "##### A Series is a one-dimensional labeled array that can hold any data type. It is similar to a column in a spreadsheet or a SQL table. It has only one axis and can be created from a list, tuple, or dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    a\n",
      "3    b\n",
      "4    c\n",
      "5    d\n",
      "6    e\n",
      "7    f\n",
      "dtype: object\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "5    f\n",
      "dtype: object\n",
      "f_name     Safin\n",
      "l_name    Arafat\n",
      "Age           18\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2     ac\n",
       "3     bd\n",
       "4     ce\n",
       "5     df\n",
       "6    NaN\n",
       "7    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Series\n",
    "alpha_List = [chr(x) for x in range(ord(\"a\"), ord(\"f\") + 1)]\n",
    "num_List = [x - 95 for x in range(ord(\"a\"), ord(\"f\") + 1)]\n",
    "\n",
    "pd_series1 = pd.Series(data=alpha_List, index=num_List)\n",
    "print(pd_series1)\n",
    "\n",
    "pd_series2 = pd.Series(alpha_List)\n",
    "print(pd_series2)\n",
    "\n",
    "\n",
    "dict_1 = {\"f_name\": \"Safin\", \"l_name\": \"Arafat\", \"Age\": 18}\n",
    "pd_series3 = pd.Series(dict_1)\n",
    "print(pd_series3)\n",
    "\n",
    "pd_series1 + pd_series2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n",
    "\n",
    "##### A DataFrame, on the other hand, is a two-dimensional labeled data structure with columns of potentially different data types. It is similar to a spreadsheet or SQL table. It has two axes (rows and columns) and can be created from a dictionary, list of lists, or a list of Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C  D  E\n",
      "a  2  0  8\n",
      "b  6  3  6\n",
      "c  1  7  7\n",
      "d  4  3  3\n",
      "   First  Second\n",
      "a    1.0       1\n",
      "b    2.0       2\n",
      "c    3.0       3\n",
      "d    NaN       4\n",
      "Empty DataFrame\n",
      "Columns: [First, Second, Third]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_arr = np.random.randint(0, 9, size=(4, 3))\n",
    "df_1 = pd.DataFrame(random_arr, [\"a\", \"b\", \"c\", \"d\"], [\"C\", \"D\", \"E\"])\n",
    "print(df_1)\n",
    "dict_2 = {\n",
    "    \"First\": pd.Series(\n",
    "        [\n",
    "            1,\n",
    "            2,\n",
    "            3,\n",
    "        ],\n",
    "        index=[\"a\", \"b\", \"c\"],\n",
    "    ),\n",
    "    \"Second\": pd.Series([1, 2, 3, 4], index=[x for x in \"abcd\"]),\n",
    "}\n",
    "\n",
    "print(pd.DataFrame.from_dict(dict_2))\n",
    "print(\n",
    "    pd.DataFrame.from_dict(dict_2, orient=\"index\", columns=[\"First\", \"Second\", \"Third\"])\n",
    ")\n",
    "\n",
    "# Dataframe is 2D Series\n",
    "type(df_1[\"C\"])  # Series\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing and Retrinving Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C  D  E\n",
      "a  2  0  8\n",
      "b  6  3  6\n",
      "c  1  7  7\n",
      "d  4  3  3\n",
      "   E  C\n",
      "a  8  2\n",
      "b  6  6\n",
      "c  7  1\n",
      "d  3  4\n",
      "7\n",
      "7\n",
      "   C  D\n",
      "d  4  3\n",
      "a  2  0\n",
      "   E  D  C\n",
      "b  6  3  6\n",
      "c  7  7  1\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Index has duplicate keys: Int64Index([15, 10], dtype='int64', name='Sum')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[320], line 17\u001b[0m\n\u001b[0;32m     12\u001b[0m pd\u001b[39m.\u001b[39mconcat([df_1, ss_1\u001b[39m.\u001b[39mto_frame()])  \u001b[39m# Concatnated after converting to dataframe\u001b[39;00m\n\u001b[0;32m     13\u001b[0m pd\u001b[39m.\u001b[39mconcat(\n\u001b[0;32m     14\u001b[0m     [df_1, ss_1\u001b[39m.\u001b[39mto_frame()\u001b[39m.\u001b[39mT]\n\u001b[0;32m     15\u001b[0m )  \u001b[39m# Concatnated after converting to dataframe and transposing\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m---> 17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, df_1\u001b[39m.\u001b[39;49mcopy()\u001b[39m.\u001b[39;49mset_index(\u001b[39m\"\u001b[39;49m\u001b[39mSum\u001b[39;49m\u001b[39m\"\u001b[39;49m, verify_integrity\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39miloc[[\u001b[39m0\u001b[39m]]\n\u001b[0;32m     18\u001b[0m )  \u001b[39m# setting first column for\u001b[39;00m\n\u001b[0;32m     20\u001b[0m df_2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mnan, \u001b[39m3\u001b[39m, np\u001b[39m.\u001b[39mnan]})\n\u001b[0;32m     21\u001b[0m df_3 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m: [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m9\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)]})\n",
      "File \u001b[1;32md:\\Python\\Python_Libraries\\env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\Python_Libraries\\env\\lib\\site-packages\\pandas\\core\\frame.py:6071\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6069\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m index\u001b[39m.\u001b[39mis_unique:\n\u001b[0;32m   6070\u001b[0m     duplicates \u001b[39m=\u001b[39m index[index\u001b[39m.\u001b[39mduplicated()]\u001b[39m.\u001b[39munique()\n\u001b[1;32m-> 6071\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIndex has duplicate keys: \u001b[39m\u001b[39m{\u001b[39;00mduplicates\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6073\u001b[0m \u001b[39m# use set to handle duplicate column names gracefully in case of drop\u001b[39;00m\n\u001b[0;32m   6074\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(to_remove):\n",
      "\u001b[1;31mValueError\u001b[0m: Index has duplicate keys: Int64Index([15, 10], dtype='int64', name='Sum')"
     ]
    }
   ],
   "source": [
    "print(df_1[:])\n",
    "print(df_1[[\"E\", \"C\"]])  # Only cols\n",
    "print(df_1.iloc[2, 2])  # rows and cols with index\n",
    "print(df_1.loc[\"c\", \"E\"])  # rows and cols with keys\n",
    "print(df_1.loc[[\"d\", \"a\"], [\"C\", \"D\"]])  # rows and cols with keys\n",
    "print(df_1.iloc[1:3, ::-1])  # Array slicing\n",
    "df_1[\"Sum\"] = df_1[\"C\"] + df_1[\"E\"] + df_1[\"D\"]\n",
    "print(pd.DataFrame(df_1).drop(columns=\"Sum\", inplace=True))  # dropping cols\n",
    "print(pd.DataFrame(df_1).drop(index=[\"b\", \"d\"], inplace=True))  # dropping rows\n",
    "ss_1 = pd.Series(data=dict_1, name=\"Values\")\n",
    "\n",
    "pd.concat([df_1, ss_1.to_frame()])  # Concatnated after converting to dataframe\n",
    "pd.concat(\n",
    "    [df_1, ss_1.to_frame().T]\n",
    ")  # Concatnated after converting to dataframe and transposing\n",
    "print(\n",
    "    \"\\n\", df_1.copy().set_index(\"Sum\", verify_integrity=True).iloc[[0]]\n",
    ")  # setting first column for\n",
    "\n",
    "df_2 = pd.DataFrame({\"A\": [1, np.nan, 3, np.nan]})\n",
    "df_3 = pd.DataFrame({\"A\": [x for x in range(9, 5, -1)]})\n",
    "df_2.combine_first(df_3)  # combines and removes nan s\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C      D     E\n",
      "A  False   True  True\n",
      "B   True  False  True\n",
      "    C    D\n",
      "A NaN  NaN\n",
      "B NaN  2.0\n"
     ]
    }
   ],
   "source": [
    "np_1 = np.random.randint(0, 9, size=(2, 3))\n",
    "df_1 = pd.DataFrame(\n",
    "    np_1,\n",
    "    [x for x in \"AB\"],\n",
    "    [x for x in \"CDE\"],\n",
    ")\n",
    "print(df_1.gt(4))\n",
    "bool4 = df_1 > 4  # creates dt with dtype: bool\n",
    "df_1[bool4]  # replace false statement with NaN\n",
    "df_1[\"E\"] > 4\n",
    "# careful not to use pd[[\"col\"]], it returns Dataframe\n",
    "# but we need series to use conditional filtering\n",
    "print(df_1[(df_1 % 2 == 0) & (df_1 > 0)][[\"C\", \"D\"]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File IO\n",
    "\n",
    "<p>File support \n",
    "<li>csv</li>\n",
    "<li>plain text</li>\n",
    "<li>json</li>\n",
    "<li>xml</li>\n",
    "<li>sql</li>\n",
    "<li>html</li>\n",
    "<li>xlsx</li>\n",
    "<li>docx</li>\n",
    "<li>zip</li>\n",
    "<li>images hierachical data</li>\n",
    "<li>mp3</li>\n",
    "<li>mp4</li>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sale ID', 'Contact', 'Sex', 'Age', 'State', 'Product ID',\n",
      "       'Product Type', 'Sale Price', 'Profit', 'Lead', 'Month', 'Year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv1 = pd.read_csv(\"./pd_data/ComputerSales.csv\")\n",
    "df_excel1 = pd.read_excel(\"./pd_data/Financial Sample.xlsx\")\n",
    "\n",
    "df_csv2 = pd.read_csv(\"./pd_data/ComputerSales.csv\")\n",
    "print(df_csv2.columns)\n",
    "df_csv2.dropna()\n",
    "mask = df_csv2[\"Sex\"] == \"M\"\n",
    "type(mask)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics and Maths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  4.,  9.,  0., 25.])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv(\"./pd_data/ComputerSales.csv\")\n",
    "df_csv.head()  # gets first 5 rows\n",
    "df_csv.tail()  # gets last 5 rows\n",
    "df_csv[:5:2]  # get 5 rows with 2 steps like 0,2,4\n",
    "df_csv.index.array  # get all the index of the rows\n",
    "df_csv.to_numpy()  # cobverts to numpy array\n",
    "\n",
    "df_1 = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\": pd.Series([1, 2, 3, 5], index=[x for x in \"abce\"]),\n",
    "        \"col2\": pd.Series([4, 5, 6, 7], index=[x for x in \"abcd\"]),\n",
    "    }\n",
    ")\n",
    "df_1 = df_1.fillna(0)  # filling empty cell with 0\n",
    "row = df_1.iloc[2]\n",
    "\n",
    "df_1.add(row, axis=1)  # add 'row' values to all rows of the data frame and\n",
    "# axis = 1 for adding it as row\n",
    "df_1.sub(row, axis=1)\n",
    "\n",
    "df_1.transform(\n",
    "    lambda x: x**2,  # trasnforms all rows\n",
    ")\n",
    "heads = df_1.columns.tolist()  # get all cols name\n",
    "# trasform can extract and modify from dataframe and create a new one\n",
    "df_1[\"col3\"] = 0\n",
    "df_1 = df_1.transform(\n",
    "    {heads[0]: lambda x: x**2, heads[1]: lambda x: x, \"col3\": lambda x: 1}\n",
    ")\n",
    "# apply specific lambda function for each cols\n",
    "\n",
    "df_1[\"col3\"] = df_1[\"col3\"].map(lambda x: x + 2)  # map works with series\n",
    "df_1[\"col1\"].unique()  # get unique value of a column\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store                         7\n",
       "Flavour    ChocVanStawChocolate\n",
       "Sales                        79\n",
       "Price                        14\n",
       "dtype: object"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = pd.DataFrame(\n",
    "    {\n",
    "        \"Store\": [1, 2, 3, 1],\n",
    "        \"Flavour\": [\"Choc\", \"Van\", \"Staw\", \"Chocolate\"],\n",
    "        \"Sales\": [26, 12, 18, 23],\n",
    "        \"Price\": [4, 5, 2, 3],\n",
    "    }\n",
    ")\n",
    "\n",
    "# eliminates duplicate targeted rows by minimum cols values\n",
    "df_3.groupby(\"Store\").min()\n",
    "\n",
    "# mean, count, standard deviation, min, max,\n",
    "df_3.describe()\n",
    "\n",
    "# Sum everything even strings\n",
    "df_3.sum()  # .loc['Store'] # only accessing Store value\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convatenate Merge & Join Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>CGPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Name  CGPA\n",
       "0   3    C  3.78\n",
       "1   4    D  2.34\n",
       "2   5    E  3.65"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame({\"id\": [x for x in range(1, 6)], \"Name\": [x for x in \"ABCDE\"]})\n",
    "\n",
    "df_2 = pd.DataFrame(\n",
    "    {\n",
    "        \"Name\": [x for x in \"CDEFG\"],\n",
    "        \"CGPA\": [round(random.random() * 4, 2) for x in range(5)],\n",
    "    }\n",
    ")\n",
    "# \"how=\" key indicates to join there is left, right, cross, outer, inner\n",
    "pd.merge(df_1, df_2, how=\"inner\", on=\"Name\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "\n",
    "There are many functions for statistics, like mean(), std() standard Deviation, var() Variant, sem(),\n",
    "skew(), kurt() etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61.166667</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.055169</td>\n",
       "      <td>105.651227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature       Sales\n",
       "mean    61.166667  400.000000\n",
       "std     17.055169  105.651227"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ics_df = pd.read_csv(\"./pd_data/icecreamsales.csv\")\n",
    "\n",
    "ics_df.count()\n",
    "\n",
    "ics_df.sum(\n",
    "    skipna=True,\n",
    ")\n",
    "\n",
    "ics_df[\"Sales\"].describe()  # shows max, mean, and other statistical values\n",
    "\n",
    "dice_rolls = pd.DataFrame([random.randint(1, 6) for x in range(20)])\n",
    "dice_rolls.value_counts()  # counts number of unique values\n",
    "ics_df.agg(\n",
    "    [\n",
    "        \"mean\",\n",
    "        \"std\",\n",
    "    ]\n",
    ")  # run custom function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration & Sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   c  d  e\n",
      "a  7  4  5\n",
      "b  5  8  2\n",
      "c  8  6  4\n",
      "c    7\n",
      "d    4\n",
      "e    5\n",
      "Name: a, dtype: int32\n",
      "c    5\n",
      "d    8\n",
      "e    2\n",
      "Name: b, dtype: int32\n",
      "c    8\n",
      "d    6\n",
      "e    4\n",
      "Name: c, dtype: int32\n",
      "Pandas(Index='a', c=7, d=4, e=5)\n",
      "Pandas(Index='b', c=5, d=8, e=2)\n",
      "Pandas(Index='c', c=8, d=6, e=4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c  d  e\n",
       "a  7  4  5\n",
       "b  5  8  2\n",
       "c  8  6  4"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_1 = pd.Series(\n",
    "    data=[random.randint(1, 9) for _ in range(5)], index=[x for x in \"abcde\"]\n",
    ")\n",
    "df = pd.DataFrame(np.random.randint(1, 9, (3, 3)), [\"a\", \"b\", \"c\"], [\"c\", \"d\", \"e\"])\n",
    "\n",
    "print(df)\n",
    "for col in ser_1:\n",
    "    # print(col)\n",
    "    ...\n",
    "\n",
    "for label, series in df.items():  # Iterating thru Cols\n",
    "    # print(ser)\n",
    "    ...\n",
    "for l, s in df.iterrows():  # iterating thru rows\n",
    "    print(s)\n",
    "\n",
    "for tup in df.itertuples():\n",
    "    print(tup)\n",
    "#\n",
    "df.sort_values(by=\"d\", kind=\"quicksort\", ascending=True)\n",
    "df.sort_index(\n",
    "    key=lambda x: x + \"_\",\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function and pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Profit: $5459.010000000001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contact</th>\n",
       "      <th>approx_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul Thomas</td>\n",
       "      <td>30~50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Margo Simms</td>\n",
       "      <td>30~50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sam Stine</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moe Eggert</td>\n",
       "      <td>30~50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jessica Elk</td>\n",
       "      <td>&gt;50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Contact approx_age\n",
       "0  Paul Thomas      30~50\n",
       "1  Margo Simms      30~50\n",
       "2    Sam Stine        <30\n",
       "3   Moe Eggert      30~50\n",
       "4  Jessica Elk        >50"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "df_com = pd.read_csv(\n",
    "    \"./pd_data/ComputerSales.csv\",\n",
    ")\n",
    "\n",
    "\n",
    "def get_profit_total(df: pd.DataFrame):\n",
    "    profit_ser = df[\"Profit\"]\n",
    "    print(f\"Total Profit: ${profit_ser.sum()}\")\n",
    "\n",
    "\n",
    "get_profit_total(df_com)\n",
    "\n",
    "\n",
    "def split_name(df: pd.DataFrame):\n",
    "    def get_name(fullName: str):\n",
    "        f_name, l_name = fullName.split()\n",
    "        return pd.Series((f_name, l_name), index=[\"First Name\", \"Last Name\"])\n",
    "\n",
    "    names = df_com[\"Contact\"].apply(get_name)\n",
    "    df[names.columns] = names\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "split_name(df_com[df_com.columns].head())\n",
    "\n",
    "\n",
    "def create_age_group(df: pd.DataFrame):\n",
    "    # if df[age] >0 and <30 then set <30 and rest are same\n",
    "    bins = [0, 30, 50, sys.maxsize]\n",
    "    labels = [\"<30\", \"30~50\", \">50\"]\n",
    "    age_group = pd.cut(\n",
    "        df[\"Age\"],\n",
    "        bins=bins,\n",
    "        labels=labels,\n",
    "    )\n",
    "    return df.assign(approx_age=pd.DataFrame(age_group))[[\"Contact\", \"approx_age\"]]\n",
    "\n",
    "\n",
    "create_age_group(df_com.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "1  2.0  NaN  8\n",
      "2  NaN  NaN  9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B  C\n",
       "0  1.0  4.0  7\n",
       "1  2.0  4.0  8\n",
       "2  2.0  4.0  9"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import nan\n",
    "\n",
    "dict_1 = {\"A\": [1, 2, nan], \"B\": [4, nan, nan], \"C\": [7, 8, 9]}\n",
    "df = pd.DataFrame(dict_1)\n",
    "print(df)\n",
    "df.dropna()  # Drop nan containing rows\n",
    "df.dropna(axis=1)  # Drop nan containing cols\n",
    "df.dropna(thresh=2)  # drop if contains 2 nan in rows\n",
    "df.fillna(value=df[\"A\"].mean())  # Fills nan with mean of col A\n",
    "df.fillna(method=\"ffill\", axis=0)  # Fills nan with the value of next row\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polars (Faster and Rust based Solution)\n",
    "\n",
    "Pandas and Polars are both data manipulation libraries for Python, but they have different design philosophies and implementation details.\n",
    "\n",
    "Pandas is a widely used library for data analysis and manipulation. It provides data structures for handling tabular and heterogeneous data, as well as a variety of functions for filtering, transforming, aggregating, and visualizing data. Pandas is built on top of NumPy and is designed to provide an easy-to-use interface for working with data, while still being highly performant for many common tasks.\n",
    "\n",
    "Polars is a newer library that is designed to provide a fast and memory-efficient alternative to Pandas, particularly for handling large datasets. Like Pandas, Polars provides data structures for handling tabular data, as well as a variety of functions for filtering, transforming, aggregating, and visualizing data. However, Polars is built on top of Rust and is designed to be highly performant, with a focus on parallelism and memory efficiency.\n",
    "\n",
    "Both libraries have similar syntax and provide similar functionality, but there are some key differences to keep in mind.\n",
    "\n",
    "- Polars is generally faster than Pandas, especially for large datasets.\n",
    "- Polars supports multi-threaded and SIMD (Single Instruction Multiple Data) operations, which can significantly speed up computation on modern CPUs.\n",
    "- Polars supports lazy evaluation, which means that computations are only performed when the results are actually needed. This can be useful for handling large datasets that do not fit in memory.\n",
    "- Pandas has a larger user community and a larger ecosystem of third-party libraries and tools.\n",
    "\n",
    "Ultimately, the choice between Pandas and Polars depends on the specific use case and the size and complexity of the data being analyzed. For small to medium-sized datasets or simpler data manipulation tasks, Pandas is likely to be sufficient and more widely adopted. For larger datasets or more complex data manipulation tasks, Polars may provide better performance and memory efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark File IO\n",
      "Pandas took     3.420000ms\n",
      "Polars took     2.270000ms\n"
     ]
    }
   ],
   "source": [
    "# pylint: disable=undefined-variable\n",
    "import polars as pl\n",
    "import time\n",
    "\n",
    "print(\"Benchmark File IO\")\n",
    "time.sleep(1.5)\n",
    "Stimer_1 = time.perf_counter()\n",
    "pd.read_csv(\"./pd_data/ComputerSales.csv\")\n",
    "Etimer_1 = time.perf_counter()\n",
    "print(f\"Pandas took {(Etimer_1 - Stimer_1)*1000:12f}ms\")\n",
    "time.sleep(1.5)\n",
    "Stimer_2 = time.perf_counter()\n",
    "pl.read_csv(\"./pd_data/ComputerSales.csv\")\n",
    "Etimer_2 = time.perf_counter()\n",
    "print(f\"Polars took {(Etimer_2 - Stimer_2)*1000:12f}ms\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
