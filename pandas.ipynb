{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "##### A Series is a one-dimensional labeled array that can hold any data type. It is similar to a column in a spreadsheet or a SQL table. It has only one axis and can be created from a list, tuple, or dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Series\n",
    "alpha_List = [chr(x) for x in range(ord(\"a\"), ord(\"f\") + 1)]\n",
    "num_List = [x - 95 for x in range(ord(\"a\"), ord(\"f\") + 1)]\n",
    "\n",
    "pd_series1 = pd.Series(data=alpha_List, index=num_List)\n",
    "print(pd_series1)\n",
    "\n",
    "pd_series2 = pd.Series(alpha_List)\n",
    "print(pd_series2)\n",
    "\n",
    "\n",
    "dict_1 = {\"f_name\": \"Safin\", \"l_name\": \"Arafat\", \"Age\": 18}\n",
    "pd_series3 = pd.Series(dict_1)\n",
    "print(pd_series3)\n",
    "\n",
    "pd_series1 + pd_series2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n",
    "\n",
    "##### A DataFrame, on the other hand, is a two-dimensional labeled data structure with columns of potentially different data types. It is similar to a spreadsheet or SQL table. It has two axes (rows and columns) and can be created from a dictionary, list of lists, or a list of Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_arr = np.random.randint(0, 9, size=(4, 3))\n",
    "df_1 = pd.DataFrame(random_arr, [\"a\", \"b\", \"c\", \"d\"], [\"C\", \"D\", \"E\"])\n",
    "print(df_1)\n",
    "dict_2 = {\n",
    "    \"First\": pd.Series(\n",
    "        [\n",
    "            1,\n",
    "            2,\n",
    "            3,\n",
    "        ],\n",
    "        index=[\"a\", \"b\", \"c\"],\n",
    "    ),\n",
    "    \"Second\": pd.Series([1, 2, 3, 4], index=[x for x in \"abcd\"]),\n",
    "}\n",
    "\n",
    "print(pd.DataFrame.from_dict(dict_2))\n",
    "print(\n",
    "    pd.DataFrame.from_dict(dict_2, orient=\"index\", columns=[\"First\", \"Second\", \"Third\"])\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing and Retrinving Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_1[:])\n",
    "print(df_1[[\"E\", \"C\"]])  # Only cols\n",
    "print(df_1.iloc[2, 2])  # rows and cols with index\n",
    "print(df_1.loc[\"c\", \"E\"])  # rows and cols with keys\n",
    "print(df_1.loc[[\"d\", \"a\"], [\"C\", \"D\"]])  # rows and cols with keys\n",
    "print(df_1.iloc[1:3, ::-1])  # Array slicing\n",
    "df_1[\"Sum\"] = df_1[\"C\"] + df_1[\"E\"] + df_1[\"D\"]\n",
    "print(pd.DataFrame(df_1).drop(columns=\"Sum\", inplace=True))  # dropping cols\n",
    "print(pd.DataFrame(df_1).drop(index=[\"b\", \"d\"], inplace=True))  # dropping rows\n",
    "ss_1 = pd.Series(data=dict_1, name=\"Values\")\n",
    "\n",
    "pd.concat([df_1, ss_1.to_frame()])  # Concatnated after converting to dataframe\n",
    "pd.concat(\n",
    "    [df_1, ss_1.to_frame().T]\n",
    ")  # Concatnated after converting to dataframe and transposing\n",
    "print('\\n',df_1.copy().set_index(\"Sum\",verify_integrity=True).iloc[[0]]) # setting first column for\n",
    "\n",
    "df_2 = pd.DataFrame({'A':[1,np.nan,3,np.nan]})\n",
    "df_3 = pd.DataFrame({'A':[x for x in range(9,5,-1)]})\n",
    "df_2.combine_first(df_3) # combines and removes nan s\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condiional Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C      D      E\n",
      "A   True  False   True\n",
      "B  False  False  False\n",
      "    C    D\n",
      "A NaN  NaN\n",
      "B NaN  2.0\n"
     ]
    }
   ],
   "source": [
    "np_1 = np.random.randint(0,9,size=(2,3))\n",
    "df_1 = pd.DataFrame(np_1,[x for x in 'AB'],[x for x in 'CDE'],)\n",
    "print(df_1.gt(4))\n",
    "bool4 = df_1 > 4 # creates dt with dtype: bool\n",
    "df_1[bool4] # replace false statement with NaN\n",
    "df_1['E'] > 4\n",
    "\n",
    "print(df_1[(df_1 % 2 == 0) & (df_1 > 0)][['C','D']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File IO\n",
    "<p>File support \n",
    "<li>csv</li>\n",
    "<li>plain text</li>\n",
    "<li>json</li>\n",
    "<li>xml</li>\n",
    "<li>sql</li>\n",
    "<li>html</li>\n",
    "<li>xlsx</li>\n",
    "<li>docx</li>\n",
    "<li>zip</li>\n",
    "<li>images hierachical data</li>\n",
    "<li>mp3</li>\n",
    "<li>mp4</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install or use the etree parser.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df_csv \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./pd_data/ComputerSales.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m df_csv\u001b[39m.\u001b[39;49mto_xml(\u001b[39m'\u001b[39;49m\u001b[39mtest.md\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Python\\Python_Libraries\\env\\lib\\site-packages\\pandas\\core\\frame.py:3402\u001b[0m, in \u001b[0;36mDataFrame.to_xml\u001b[1;34m(self, path_or_buffer, index, root_name, row_name, na_rep, attr_cols, elem_cols, namespaces, prefix, encoding, xml_declaration, pretty_print, parser, stylesheet, compression, storage_options)\u001b[0m\n\u001b[0;32m   3400\u001b[0m         TreeBuilder \u001b[39m=\u001b[39m LxmlXMLFormatter\n\u001b[0;32m   3401\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3402\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   3403\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlxml not found, please install or use the etree parser.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3404\u001b[0m         )\n\u001b[0;32m   3406\u001b[0m \u001b[39melif\u001b[39;00m parser \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39metree\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   3407\u001b[0m     TreeBuilder \u001b[39m=\u001b[39m EtreeXMLFormatter\n",
      "\u001b[1;31mImportError\u001b[0m: lxml not found, please install or use the etree parser."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
